{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4yf93cBgiW2f"
   },
   "source": [
    "# Process data from PDC assays\n",
    "## Notes\n",
    "DO 1-26-2026 I'm re-creating this file with the help of claude code\n",
    "\n",
    "## Analysis plan\n",
    "* Load the \"Enzyme_assay_metadata\" spreadsheet and identify the assays we want to process\n",
    "* Find all of the .csv files with PDC enzyme assay data\n",
    "* For each csv file:\n",
    "  * Add filename information\n",
    "  * Measure initial pyruvate\n",
    "    * Determine the expected initial pyruvate concentration (Pyruvate_mM) and Blank_time_s from the Enzyme_assay_metadata dataframe\n",
    "    * Calculate the pyruvate concentration using the _calculate_blank_pyruvate() function imported from the \"Compiling_spectrum_data.ipynb\" notebook in the \"Spectrum files from Agilent spec\" folder\n",
    "    * If the difference from the expected pyruvate concentration is >50%, throw a warning and use the expected pyruvate concentration instead (note, it might make senese to update this in the _calculate_blank_pyruvate() function\n",
    "  * Measure NADH concentration\n",
    "    * use the process_pdc_timecourse() function\n",
    "\n",
    "* Combine the data into a single pandas dataframe for plotting\n",
    "* Plot NADH concentration vs. offset time (i.e. where the assay start time has been shifted to zero) for all samples. This will allow us to do a rough examination of the data\n",
    "\n",
    "* Data processing for subsequent analysis:\n",
    "  * For each assay, measure the maximum slope (V), after the assay start.\n",
    "  * Normalize V to the enzyme concentration (V/E)\n",
    "\n",
    "* Determine the effect of Adh enzyme concentration\n",
    "  * Select only the \"Varying Adh\" assay group\n",
    "  * Plot V/E vs. the Adh concentration\n",
    "\n",
    "* Create a kcat plot\n",
    "  * Plot V/E vs. the substrate concentration\n",
    "  * Adjust the units so that we can measure kcat directly from the plot\n",
    "  * Color by filename\n",
    "\n",
    "* Measure NADH degradation (see if we have good enough data for this)\n",
    "\n",
    "* Convert to an EnzymeML file\n",
    "* Upload EnzymeML file, colab notebook, and raw data to Janis Shin's github folder for subsequent modeling.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Setup complete! Imported all required modules.\n",
      "Autoreload enabled - modules will be reloaded automatically.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# Add parent directory to path to import pda modules\n",
    "parent_path = str(Path.cwd().parent.parent)\n",
    "if parent_path not in sys.path:\n",
    "    sys.path.insert(0, parent_path)\n",
    "\n",
    "from pda.data_io import load_kinetic_data\n",
    "from pda.spectral import calculate_concentrations\n",
    "from pda.timecourse import process_pdc_timecourse\n",
    "\n",
    "print(\"Setup complete! Imported all required modules.\")\n",
    "print(\"Autoreload enabled - modules will be reloaded automatically.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 129 assays from metadata\n",
      "Loaded 858 wavelength points from standards\n"
     ]
    }
   ],
   "source": [
    "# Load metadata\n",
    "metadata_url = \"https://docs.google.com/spreadsheets/d/e/2PACX-1vRVpwYqImFkaUigsWgrO9MRtWjYWwps82EExnomLqNr_hOUNViKF_fFyAhJfIqe3hDq0IEG76W4v_fO/pub?output=csv\"\n",
    "metadata_df = pd.read_csv(metadata_url)\n",
    "\n",
    "# Load standards\n",
    "standards_df = pd.read_csv(\"../spectra_data/NADH_Pyruvate_Standards.csv\")\n",
    "\n",
    "print(f\"Loaded {len(metadata_df)} assays from metadata\")\n",
    "print(f\"Loaded {len(standards_df)} wavelength points from standards\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 96 PDC assays to process\n",
      "Assay groups: ['Varying Adh' 'Varying pyr low NADH' 'Varying pyr high NADH']\n",
      "Unique files: 32\n"
     ]
    }
   ],
   "source": [
    "# Filter for PDC forward assays that are not flagged to ignore\n",
    "pdc_assays = metadata_df[\n",
    "    (metadata_df['Assay'] == 'PDC_fwd') & \n",
    "    (metadata_df['Ignore'].isna())\n",
    "].copy()\n",
    "\n",
    "print(f\"Found {len(pdc_assays)} PDC assays to process\")\n",
    "print(f\"Assay groups: {pdc_assays['Assay Group'].unique()}\")\n",
    "print(f\"Unique files: {pdc_assays['Filename'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total PDC assays: 96\n",
      "CSV files found: 66\n",
      "CSV files missing: 30\n",
      "Missing files:\n",
      "['0116 1600 800 400MM PYR-1.csv' '0116 200 100 40MM PYR-2.csv'\n",
      " '0116 20 16 8 4MM PYR-4.csv' '0120 1600 800 400MM PYR-1.csv'\n",
      " '0120 200 100 40MM PYR-2.csv' '0120 20 16 8 4MM PYR-3.csv'\n",
      " '0121 1600 800 400MM PYR-1.csv' '0121 200 100 40MM PYR-2.csv'\n",
      " '0121 20 16 8 4MM PYR-3.csv']\n",
      "Processing 66 assays with available CSV files\n"
     ]
    }
   ],
   "source": [
    "# Create mapping from metadata filenames (.KD) to actual CSV files\n",
    "assay_data_path = Path(\"../assay_data\")\n",
    "\n",
    "# Add CSV filename column\n",
    "pdc_assays['csv_filename'] = pdc_assays['Filename'].str.replace('.KD', '.csv', regex=False)\n",
    "\n",
    "# Check which files exist\n",
    "pdc_assays['csv_exists'] = pdc_assays['csv_filename'].apply(\n",
    "    lambda x: (assay_data_path / x).exists()\n",
    ")\n",
    "\n",
    "print(f\"Total PDC assays: {len(pdc_assays)}\")\n",
    "print(f\"CSV files found: {pdc_assays['csv_exists'].sum()}\")\n",
    "print(f\"CSV files missing: {(~pdc_assays['csv_exists']).sum()}\")\n",
    "\n",
    "if (~pdc_assays['csv_exists']).any():\n",
    "    print(\"Missing files:\")\n",
    "    print(pdc_assays[~pdc_assays['csv_exists']]['csv_filename'].unique())\n",
    "\n",
    "# Filter to only assays with existing CSV files\n",
    "pdc_assays = pdc_assays[pdc_assays['csv_exists']].copy()\n",
    "print(f\"Processing {len(pdc_assays)} assays with available CSV files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debugging one dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# DEBUG: Test processing of a specific dataset\nimport traceback\n\n# Get a specific assay from metadata for testing\ntest_assay = pdc_assays[\n    (pdc_assays['csv_filename'] == '1222 PDC-9.csv') & \n    (pdc_assays['Cuvette'] == 'CELL_2')\n].iloc[0]\n\nprint(f\"Testing: {test_assay['csv_filename']} - {test_assay['Cuvette']}\")\nprint(f\"Pyruvate: {test_assay['Pyruvate_mM']} mM\")\nprint(f\"Start: {test_assay['Start_time_s']} s\")\nprint(f\"Blank: {test_assay['Blank_time_s']} s\")\nprint()\n\ntry:\n    # Load the data\n    csv_path = assay_data_path / test_assay['csv_filename']\n    print(f\"Loading from: {csv_path}\")\n    spectral_df = load_kinetic_data(str(csv_path), sample_filter=test_assay['Cuvette'])\n    \n    print(f\"Loaded dataframe shape: {spectral_df.shape}\")\n    print(f\"First few rows:\")\n    print(spectral_df.head())\n    print()\n    \n    # Process timecourse\n    print(\"Calling process_pdc_timecourse...\")\n    results = process_pdc_timecourse(\n        spectral_df=spectral_df,\n        standards_df=standards_df,\n        assay_start_time=test_assay['Start_time_s'],\n        blank_time=test_assay['Blank_time_s'],\n        initial_pyruvate_mM=test_assay['Pyruvate_mM'],\n        method='constrained',\n        wavelength_range=(320, 420),\n        absorbance_max=2,\n        plot=True,\n        verbose=True  # Turn on verbose for debugging\n    )\n    \n    print(f\"\\n✓ Success! Processed {len(results)} time points\")\n    print(results.head())\n    \nexcept Exception as e:\n    print(f\"ERROR: {e}\")\n    print(f\"Full traceback:\")\n    traceback.print_exc()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process each PDC assay using process_pdc_timecourse()\n",
    "import traceback\n",
    "\n",
    "all_results = []\n",
    "errors = []\n",
    "\n",
    "for idx, assay in pdc_assays.iterrows():\n",
    "    csv_path = assay_data_path / assay['csv_filename']\n",
    "    \n",
    "    print(f\"Processing: {assay['csv_filename']} - {assay['Cuvette']}\")\n",
    "    print(f\"  Pyruvate: {assay['Pyruvate_mM']} mM, Start: {assay['Start_time_s']} s, Blank: {assay['Blank_time_s']} s\")\n",
    "    \n",
    "    try:\n",
    "        # Load CSV file\n",
    "        spectral_df = load_kinetic_data(str(csv_path), sample_filter=assay['Cuvette'])\n",
    "        \n",
    "        print(f\"  Loaded {len(spectral_df)} rows for {assay['Cuvette']}\")\n",
    "        \n",
    "        if len(spectral_df) == 0:\n",
    "            msg = f\"No data found for {assay['Cuvette']}\"\n",
    "            print(f\"  WARNING: {msg}\")\n",
    "            errors.append({\n",
    "                'filename': assay['csv_filename'],\n",
    "                'cuvette': assay['Cuvette'],\n",
    "                'error': msg\n",
    "            })\n",
    "            continue\n",
    "        \n",
    "        # Process timecourse\n",
    "        results = process_pdc_timecourse(\n",
    "            spectral_df=spectral_df,\n",
    "            standards_df=standards_df,\n",
    "            assay_start_time=assay['Start_time_s'],\n",
    "            blank_time=assay['Blank_time_s'],\n",
    "            initial_pyruvate_mM=assay['Pyruvate_mM'],\n",
    "            method='constrained',\n",
    "            wavelength_range=(320, 420),\n",
    "            absorbance_max=2,\n",
    "            plot=True,\n",
    "            verbose=False\n",
    "        )\n",
    "        \n",
    "        # Add metadata columns\n",
    "        results['Filename'] = assay['Filename']\n",
    "        results['csv_filename'] = assay['csv_filename']\n",
    "        results['Cuvette'] = assay['Cuvette']\n",
    "        results['Assay_Group'] = assay['Assay Group']\n",
    "        results['Pdc_ug_ml'] = assay['Pdc_ug_ml']\n",
    "        results['Adh_ug_ml'] = assay['Adh_ug_ml']\n",
    "        \n",
    "        all_results.append(results)\n",
    "        \n",
    "        print(f\"  ✓ Processed {len(results)} time points\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        msg = str(e)\n",
    "        print(f\"  ERROR: {msg}\")\n",
    "        print(f\"  Full traceback:\")\n",
    "        traceback.print_exc()\n",
    "        errors.append({\n",
    "            'filename': assay['csv_filename'],\n",
    "            'cuvette': assay['Cuvette'],\n",
    "            'error': msg\n",
    "        })\n",
    "        continue\n",
    "\n",
    "# Combine all results\n",
    "if len(all_results) > 0:\n",
    "    combined_df = pd.concat(all_results, ignore_index=True)\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Successfully processed {len(all_results)} assays\")\n",
    "    print(f\"Total time points: {len(combined_df)}\")\n",
    "    if len(errors) > 0:\n",
    "        print(f\"Errors encountered: {len(errors)}\")\n",
    "    print(f\"{'='*60}\")\n",
    "else:\n",
    "    print(\"No results to combine!\")\n",
    "    combined_df = pd.DataFrame()\n",
    "\n",
    "# Show error summary if any\n",
    "if len(errors) > 0:\n",
    "    print(f\"{'='*60}\")\n",
    "    print(\"ERROR SUMMARY:\")\n",
    "    print(f\"{'='*60}\")\n",
    "    errors_df = pd.DataFrame(errors)\n",
    "    print(errors_df.to_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot NADH concentration vs. time for all assays\n",
    "combined_df['Assay_ID'] = combined_df['Cuvette'] + '_' + combined_df['csv_filename']\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "for assay_id in combined_df['Assay_ID'].unique():\n",
    "    data = combined_df[combined_df['Assay_ID'] == assay_id]\n",
    "    \n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=data['Time_Relative_s'],\n",
    "        y=data['NADH_mM'],\n",
    "        mode='lines',\n",
    "        name=assay_id,\n",
    "        showlegend=True\n",
    "    ))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='NADH Concentration vs. Time (All PDC Assays)',\n",
    "    xaxis_title='Time from Assay Start (s)',\n",
    "    yaxis_title='NADH Concentration (mM)',\n",
    "    height=600,\n",
    "    hovermode='closest'\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "print(f\"Plotted {combined_df['Assay_ID'].nunique()} assays\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate V (maximum slope) and V/E for each assay\n",
    "from scipy.stats import linregress\n",
    "\n",
    "# Time window for initial rate calculation (seconds after assay start)\n",
    "RATE_WINDOW_START = 0\n",
    "RATE_WINDOW_END = 50\n",
    "\n",
    "kinetic_results = []\n",
    "\n",
    "for assay_id in combined_df['Assay_ID'].unique():\n",
    "    assay_data = combined_df[combined_df['Assay_ID'] == assay_id].copy()\n",
    "    \n",
    "    # Filter to rate window\n",
    "    rate_data = assay_data[\n",
    "        (assay_data['Time_Relative_s'] >= RATE_WINDOW_START) &\n",
    "        (assay_data['Time_Relative_s'] <= RATE_WINDOW_END)\n",
    "    ]\n",
    "    \n",
    "    if len(rate_data) < 3:\n",
    "        print(f\"Warning: Not enough data points for {assay_id}\")\n",
    "        continue\n",
    "    \n",
    "    # Calculate slope using linear regression\n",
    "    slope, intercept, r_value, p_value, std_err = linregress(\n",
    "        rate_data['Time_Relative_s'],\n",
    "        rate_data['NADH_mM']\n",
    "    )\n",
    "    \n",
    "    # Get metadata\n",
    "    metadata = assay_data.iloc[0]\n",
    "    pdc_conc = metadata['Pdc_ug_ml']\n",
    "    \n",
    "    # Calculate V/E (normalize by enzyme concentration)\n",
    "    if pd.notna(pdc_conc) and pdc_conc > 0:\n",
    "        v_over_e = slope / pdc_conc\n",
    "    else:\n",
    "        v_over_e = np.nan\n",
    "    \n",
    "    kinetic_results.append({\n",
    "        'Assay_ID': assay_id,\n",
    "        'Filename': metadata['Filename'],\n",
    "        'csv_filename': metadata['csv_filename'],\n",
    "        'Cuvette': metadata['Cuvette'],\n",
    "        'Assay_Group': metadata['Assay_Group'],\n",
    "        'Pdc_ug_ml': pdc_conc,\n",
    "        'Adh_ug_ml': metadata['Adh_ug_ml'],\n",
    "        'Pyruvate_mM': metadata['Pyruvate_mM'],\n",
    "        'V_mM_per_s': slope,\n",
    "        'V_over_E': v_over_e,\n",
    "        'Intercept_mM': intercept,\n",
    "        'R_squared': r_value**2,\n",
    "        'n_points': len(rate_data)\n",
    "    })\n",
    "\n",
    "kinetics_df = pd.DataFrame(kinetic_results)\n",
    "\n",
    "print(f\"Calculated kinetics for {len(kinetics_df)} assays\")\n",
    "print(f\"\n",
    "Summary statistics for V/E:\")\n",
    "print(kinetics_df['V_over_E'].describe())\n",
    "print(f\"\n",
    "Assay groups: {kinetics_df['Assay_Group'].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot individual assay timecourses with regression lines\n",
    "n_plots = min(6, len(kinetics_df))\n",
    "sample_assays = kinetics_df.head(n_plots)\n",
    "\n",
    "for idx, row in sample_assays.iterrows():\n",
    "    assay_id = row['Assay_ID']\n",
    "    assay_data = combined_df[combined_df['Assay_ID'] == assay_id]\n",
    "    \n",
    "    # Create regression line points\n",
    "    x_line = np.array([RATE_WINDOW_START, RATE_WINDOW_END])\n",
    "    y_line = row['V_mM_per_s'] * x_line + row['Intercept_mM']\n",
    "    \n",
    "    # Create plot\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    # Add full timecourse\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=assay_data['Time_Relative_s'],\n",
    "        y=assay_data['NADH_mM'],\n",
    "        mode='markers',\n",
    "        name='Data',\n",
    "        marker=dict(size=4, color='blue')\n",
    "    ))\n",
    "    \n",
    "    # Add regression line\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=x_line,\n",
    "        y=y_line,\n",
    "        mode='lines',\n",
    "        name=f'Linear fit (V/E = {row[\"V_over_E\"]:.6f})',\n",
    "        line=dict(color='red', width=2)\n",
    "    ))\n",
    "    \n",
    "    # Add shaded region for rate window\n",
    "    fig.add_vrect(\n",
    "        x0=RATE_WINDOW_START,\n",
    "        x1=RATE_WINDOW_END,\n",
    "        fillcolor='lightgray',\n",
    "        opacity=0.2,\n",
    "        line_width=0,\n",
    "        annotation_text=\"Rate window\",\n",
    "        annotation_position=\"top left\"\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=f'{row[\"Cuvette\"]} - {row[\"csv_filename\"]}<br>' + \n",
    "              f'V = {row[\"V_mM_per_s\"]:.6f} mM/s, ' +\n",
    "              f'V/E = {row[\"V_over_E\"]:.6f} mM/s/(μg/mL), ' +\n",
    "              f'R² = {row[\"R_squared\"]:.4f}',\n",
    "        xaxis_title='Time from Assay Start (s)',\n",
    "        yaxis_title='NADH Concentration (mM)',\n",
    "        height=400,\n",
    "        showlegend=True\n",
    "    )\n",
    "    \n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot V/E vs. ADH concentration for \"Varying Adh\" assay group\n",
    "varying_adh = kinetics_df[kinetics_df['Assay_Group'] == 'Varying Adh'].copy()\n",
    "\n",
    "if len(varying_adh) > 0:\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    # Add scatter points\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=varying_adh['Adh_ug_ml'],\n",
    "        y=varying_adh['V_over_E'],\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=10,\n",
    "            color=varying_adh['R_squared'],\n",
    "            colorscale='Viridis',\n",
    "            showscale=True,\n",
    "            colorbar=dict(title='R²'),\n",
    "            line=dict(width=1, color='black')\n",
    "        ),\n",
    "        text=[f\"{row['Cuvette']}<br>{row['csv_filename']}<br>R²={row['R_squared']:.3f}\" \n",
    "              for _, row in varying_adh.iterrows()],\n",
    "        hovertemplate='ADH: %{x:.3f} μg/mL<br>V/E: %{y:.6f}<br>%{text}<extra></extra>'\n",
    "    ))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title='Effect of ADH Concentration on PDC Reaction Rate<br>(Varying Adh Assay Group)',\n",
    "        xaxis_title='ADH Concentration (μg/mL)',\n",
    "        yaxis_title='V/E (mM/s per μg/mL PDC)',\n",
    "        height=500,\n",
    "        showlegend=False\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "    \n",
    "    print(f\"\n",
    "Varying Adh group statistics:\")\n",
    "    print(f\"  Number of assays: {len(varying_adh)}\")\n",
    "    print(f\"  ADH range: {varying_adh['Adh_ug_ml'].min():.3f} - {varying_adh['Adh_ug_ml'].max():.3f} μg/mL\")\n",
    "    print(f\"  V/E range: {varying_adh['V_over_E'].min():.6f} - {varying_adh['V_over_E'].max():.6f}\")\n",
    "else:\n",
    "    print(\"No 'Varying Adh' assays found in the dataset\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "enzykit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}